% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate.R
\name{evaluate}
\alias{evaluate}
\alias{evaluate_active_file}
\title{Evaluate LLM performance}
\usage{
evaluate(path = ".", across = tibble(), repeats = 1L, ...)

evaluate_active_file(
  path = active_eval_file(),
  across = tibble(),
  repeats = 1L,
  ...
)
}
\arguments{
\item{path}{Path to the directory or file containing the evaluation code.}

\item{across}{A data frame where each column represents an option to be set
when evaluating the file at \code{path} and each row represents a pass through
that file.}

\item{repeats}{A single positive integer specifying the number of
evaluation repeats, or runs over the same test files. Assuming that the
models you're evaluating provide non-deterministic output, running the
same test files multiple times by setting \code{repeats > 1} will help you
quantify the variability of your evaluations.}

\item{...}{Additional arguments passed to internal functions.}
}
\value{
Results of the evaluation, invisibly. Evaluation results contain information
on the eval metadata as well as numbers of failures
and passes, input and output, and descriptions of each failure.

The function also has side-effects:
\itemize{
\item An interactive progress interface tracking results in real-time.
\item \emph{Result files} are stored in \verb{dirname(path)/_results}. Result files contain
persistent, fine-grained evaluation results and can be interfaced with
via \code{\link[=results_read]{results_read()}} and friends.
}
}
\description{
\code{evaluate()} and \code{evaluate_active_file()} are roughly analogous to
\code{\link[devtools:test]{devtools::test()}} and \code{\link[devtools:test]{devtools::test_active_file()}}, though note that
\code{evaluate()} can take either a directory of files or a single file.
}
\examples{
\dontshow{if (FALSE) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# evaluate with the default model twice
evaluate("tests/evalthat/test-ggplot2.R", repeats = 2)

# evaluate a directory of evals across several models,
# repeating each eval twice
eval <- evaluate(
  "tests/evalthat/test-ggplot2.R",
  across = tibble(chat = c(
    chat_openai(model = "gpt-4o-mini", echo = FALSE),
    chat_claude(model = "claude-3-5-sonnet-latest", echo = FALSE))
  ),
  repeats = 2
)
\dontshow{\}) # examplesIf}
}
