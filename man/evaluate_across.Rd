% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate-across.R
\name{evaluate_across}
\alias{evaluate_across}
\title{Evaluate LLM performance across models/prompts/etc}
\usage{
evaluate_across(path = ".", across = tibble(), repeats = 1L, ...)
}
\arguments{
\item{path}{Path to the directory or file in question. Optional.}

\item{across}{A data frame where each column represents an option to be set
when evaluating the file at \code{path} and each row represents a pass through
that file.}

\item{repeats}{A single positive integer specifying the number of
evaluation repeats, or runs over the same test files.}

\item{...}{Additional arguments passed to \code{testthat:::test_files()}.}
}
\description{
\code{evaluate_across()} is an extension of \code{\link[=evaluate]{evaluate()}} and friends that
allows users to run evals across various combinations of models, prompts,
or any other arbitrary parameter.
}
\examples{
\dontshow{if (FALSE) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# evaluate a directory of evals across several models
evaluate_across(
  tibble::tribble(
    ~provider,          ~model,
    elmer::chat_openai, "gpt-4o",
    elmer::chat_openai, "gpt-4o-mini",
    elmer::chat_claude, "claude-3-5-sonnet-latest",
    elmer::chat_ollama, "qwen2.5-coder:14b"
  )
)

# in the eval file, write...
```r
provider <- getOption("provider", default = elmer::chat_claude)
model <- getOption("model", default = "claude-3-5-sonnet-latest")

chat <- provider(model = model)

# ... and so on
```
\dontshow{\}) # examplesIf}
}
